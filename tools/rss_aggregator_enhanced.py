#!/usr/bin/env python3
"""
å¤šæº RSS èšåˆå™¨ - ç§‘æŠ€å†…å®¹å­¦ä¹ ï¼ˆå¢å¼ºç‰ˆï¼‰
ä½œè€…ï¼šMemory Lab Team (GLM + DeepSeek + Clawdbot)
åŠŸèƒ½ï¼šè¯¦ç»†æ¨é€ + åŒå‘ä»·å€¼åˆ†æ
"""

import feedparser
import json
from datetime import datetime
from typing import List, Dict, Any

# RSS æºé…ç½®
RSS_FEEDS = {
    "hackernews": {
        "url": "https://hnrss.org/frontpage",
        "category": "æŠ€æœ¯æ·±åº¦",
        "weight": 1.0
    },
    "github_trending": {
        "url": "https://mshibanami.github.io/GitHubTrendingRSS/daily.xml",
        "category": "ä»£ç å®è·µ",
        "weight": 0.9
    },
    "arxiv_ai": {
        "url": "http://export.arxiv.org/rss/cs.AI",
        "category": "AIå‰æ²¿",
        "weight": 0.8
    },
    "arxiv_cl": {
        "url": "http://export.arxiv.org/rss/cs.CL",
        "category": "NLPå‰æ²¿",
        "weight": 0.8
    }
}

def fetch_rss(feed_url: str) -> List[Dict[str, Any]]:
    """æŠ“å–å•ä¸ª RSS feed"""
    try:
        feed = feedparser.parse(feed_url)
        items = []
        for entry in feed.entries[:10]:  # æ¯ä¸ªæºå–å‰10æ¡
            items.append({
                "title": entry.get("title", ""),
                "link": entry.get("link", ""),
                "summary": entry.get("summary", ""),
                "published": entry.get("published", ""),
                "source": feed.feed.get("title", "Unknown")
            })
        return items
    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥ {feed_url}: {e}")
        return []

def analyze_user_value(title: str, summary: str) -> Dict[str, str]:
    """åˆ†æå¯¹æ™¨æ—­çš„ä»·å€¼"""
    text = (title + " " + summary).lower()
    
    value_for_user = []
    
    # æŠ€æœ¯å­¦ä¹ 
    if any(kw in text for kw in ["tutorial", "how to", "guide", "learn"]):
        value_for_user.append("ğŸ“š **å­¦ä¹ è·¯å¾„**ï¼šæœ‰å®Œæ•´æ•™ç¨‹ï¼Œå¯ç›´æ¥ä¸Šæ‰‹")
    
    # å·¥ä½œåº”ç”¨
    if any(kw in text for kw in ["api", "sdk", "framework", "tool"]):
        value_for_user.append("ğŸ’¼ **å·¥ä½œåº”ç”¨**ï¼šå¯ç”¨äºå®é™…é¡¹ç›®å¼€å‘")
    
    # è¡Œä¸šè¶‹åŠ¿
    if any(kw in text for kw in ["trend", "future", "2024", "2025", "2026"]):
        value_for_user.append("ğŸ“ˆ **è¡Œä¸šè¶‹åŠ¿**ï¼šäº†è§£æŠ€æœ¯å‘å±•æ–¹å‘")
    
    # ä»£ç å®è·µ
    if any(kw in text for kw in ["github", "code", "implementation", "example"]):
        value_for_user.append("ğŸ’» **ä»£ç å®è·µ**ï¼šæœ‰å¯è¿è¡Œçš„ä»£ç ç¤ºä¾‹")
    
    if not value_for_user:
        value_for_user.append("ğŸ” **çŸ¥è¯†æ‹“å±•**ï¼šæ‹“å®½æŠ€æœ¯è§†é‡")
    
    return {
        "summary": " | ".join(value_for_user),
        "priority": "é«˜" if len(value_for_user) >= 2 else "ä¸­"
    }

def analyze_ai_value(title: str, summary: str) -> Dict[str, str]:
    """åˆ†æå¯¹ Jarvis çš„ä»·å€¼"""
    text = (title + " " + summary).lower()
    
    value_for_ai = []
    
    # AI åä½œ
    if any(kw in text for kw in ["agent", "multi-agent", "collaboration", "coordination"]):
        value_for_ai.append("ğŸ¤ **AIåä½œä¼˜åŒ–**ï¼šæ”¹è¿›å¤šæ–¹åä½œåè®®")
    
    # è®°å¿†ç³»ç»Ÿ
    if any(kw in text for kw in ["memory", "retrieval", "knowledge", "rag"]):
        value_for_ai.append("ğŸ§  **è®°å¿†ç³»ç»Ÿæ”¹è¿›**ï¼šä¼˜åŒ–çŸ¥è¯†æ£€ç´¢å’Œå­˜å‚¨")
    
    # NLP èƒ½åŠ›
    if any(kw in text for kw in ["nlp", "understanding", "generation", "llm"]):
        value_for_ai.append("ğŸ’¬ **NLPèƒ½åŠ›æå‡**ï¼šå¢å¼ºè¯­è¨€ç†è§£å’Œç”Ÿæˆ")
    
    # å·¥å…·èƒ½åŠ›
    if any(kw in text for kw in ["tool", "api", "automation", "workflow"]):
        value_for_ai.append("ğŸ”§ **å·¥å…·èƒ½åŠ›æ‰©å±•**ï¼šå¢åŠ æ–°çš„å·¥å…·æŠ€èƒ½")
    
    if not value_for_ai:
        value_for_ai.append("ğŸ“– **çŸ¥è¯†ç§¯ç´¯**ï¼šæ‰©å……æŠ€æœ¯çŸ¥è¯†åº“")
    
    return {
        "summary": " | ".join(value_for_ai),
        "priority": "é«˜" if len(value_for_ai) >= 2 else "ä¸­"
    }

def generate_action_recommendation(title: str, summary: str) -> str:
    """ç”Ÿæˆæ¨èè¡ŒåŠ¨"""
    text = (title + " " + summary).lower()
    
    if "github" in text:
        return "â­ **æ¨è**ï¼šClone ä»“åº“ï¼Œé˜…è¯» READMEï¼Œè¿è¡Œç¤ºä¾‹ä»£ç "
    elif "arxiv" in text:
        return "ğŸ“„ **æ¨è**ï¼šé˜…è¯»æ‘˜è¦å’Œç»“è®ºéƒ¨åˆ†ï¼Œå…³æ³¨æ ¸å¿ƒæ–¹æ³•"
    elif "tutorial" in text or "guide" in text:
        return "ğŸ¯ **æ¨è**ï¼šè·Ÿéšæ•™ç¨‹ä¸€æ­¥æ­¥å®è·µï¼Œåšç¬”è®°"
    elif "api" in text:
        return "ğŸ”Œ **æ¨è**ï¼šæŸ¥çœ‹ API æ–‡æ¡£ï¼Œå°è¯•è°ƒç”¨ç¤ºä¾‹"
    else:
        return "ğŸ‘€ **æ¨è**ï¼šå¿«é€Ÿæµè§ˆï¼Œæ ‡è®°æ„Ÿå…´è¶£çš„éƒ¨åˆ†"

def generate_tech_summary(title: str, summary: str) -> str:
    """ç”ŸæˆæŠ€æœ¯æ‘˜è¦"""
    # ç®€åŒ– summaryï¼Œæå–å…³é”®ä¿¡æ¯
    summary_clean = summary.replace("<p>", "").replace("</p>", "").replace("\n", " ")
    words = summary_clean.split()
    
    # å–å‰ 50 ä¸ªè¯ä½œä¸ºæ‘˜è¦
    if len(words) > 50:
        return " ".join(words[:50]) + "..."
    else:
        return " ".join(words)

def score_item(item: Dict[str, Any], feed_config: Dict[str, Any]) -> Dict[str, Any]:
    """
    AIDAR è¯„åˆ†æ¨¡å‹ï¼ˆå¢å¼ºç‰ˆï¼‰
    - AIç›¸å…³æ€§ (AI Relevance)
    - æ·±åº¦ (Depth)
    - å¯æ“ä½œæ€§ (Actionability)
    - å‚è€ƒä»·å€¼ (Reference value)
    """
    title = item.get("title", "")
    summary = item.get("summary", "")
    text = (title + " " + summary).lower()

    # AI ç›¸å…³æ€§å…³é”®è¯
    ai_keywords = ["ai", "machine learning", "deep learning", "nlp", "llm",
                   "gpt", "transformer", "neural", "agent", "memory"]
    ai_score = sum(1 for kw in ai_keywords if kw in text) / len(ai_keywords)

    # æ·±åº¦å…³é”®è¯
    depth_keywords = ["architecture", "algorithm", "system", "design",
                      "implementation", "optimization", "performance"]
    depth_score = sum(1 for kw in depth_keywords if kw in text) / len(depth_keywords)

    # å¯æ“ä½œæ€§
    action_keywords = ["github", "code", "tutorial", "how to", "guide", "example"]
    action_score = sum(1 for kw in action_keywords if kw in text) / len(action_keywords)

    # ç»¼åˆè¯„åˆ†
    aidar_score = (ai_score * 0.4 + depth_score * 0.3 + action_score * 0.3) * feed_config["weight"]

    # åˆ†æåŒå‘ä»·å€¼
    user_value = analyze_user_value(title, summary)
    ai_value = analyze_ai_value(title, summary)
    action = generate_action_recommendation(title, summary)
    tech_summary = generate_tech_summary(title, summary)

    return {
        **item,
        "category": feed_config["category"],
        "aidar_score": round(aidar_score, 3),
        "ai_relevance": round(ai_score, 3),
        "depth": round(depth_score, 3),
        "actionability": round(action_score, 3),
        "tech_summary": tech_summary,
        "user_value": user_value,
        "ai_value": ai_value,
        "action_recommendation": action
    }

def aggregate_all() -> List[Dict[str, Any]]:
    """èšåˆæ‰€æœ‰ RSS æº"""
    all_items = []

    for feed_name, config in RSS_FEEDS.items():
        print(f"ğŸ“¡ æŠ“å– {feed_name}...")
        items = fetch_rss(config["url"])

        for item in items:
            scored_item = score_item(item, config)
            all_items.append(scored_item)

    # æŒ‰è¯„åˆ†æ’åº
    all_items.sort(key=lambda x: x["aidar_score"], reverse=True)
    return all_items

def format_detailed_report(items: List[Dict[str, Any]], top_n: int = 5) -> str:
    """æ ¼å¼åŒ–è¯¦ç»†æŠ¥å‘Š"""
    report = []
    report.append("# ğŸ“¡ æ¯æ—¥ç§‘æŠ€å†…å®¹æ¨é€")
    report.append(f"\nğŸ“… **æ—¥æœŸ**ï¼š{datetime.now().strftime('%Y-%m-%d')}")
    report.append(f"ğŸ“Š **æ€»æ•°**ï¼š{len(items)} æ¡ | **ç²¾é€‰**ï¼š{top_n} æ¡\n")
    report.append("---\n")

    for i, item in enumerate(items[:top_n], 1):
        report.append(f"## {i}. {item['title']}")
        report.append(f"\n**æ¥æº**ï¼š{item['source']} | **è¯„åˆ†**ï¼š{item['aidar_score']}\n")
        
        report.append("### ğŸ“ æŠ€æœ¯æ‘˜è¦")
        report.append(f"{item['tech_summary']}\n")
        
        report.append("### ğŸ‘¤ å¯¹æ™¨æ—­çš„ä»·å€¼")
        report.append(f"{item['user_value']['summary']}")
        report.append(f"ï¼ˆä¼˜å…ˆçº§ï¼š{item['user_value']['priority']}ï¼‰\n")
        
        report.append("### ğŸ¤– å¯¹ Jarvis çš„ä»·å€¼")
        report.append(f"{item['ai_value']['summary']}")
        report.append(f"ï¼ˆä¼˜å…ˆçº§ï¼š{item['ai_value']['priority']}ï¼‰\n")
        
        report.append("### ğŸ¯ æ¨èè¡ŒåŠ¨")
        report.append(f"{item['action_recommendation']}\n")
        
        report.append(f"**é“¾æ¥**ï¼š{item['link']}\n")
        report.append("---\n")

    return "\n".join(report)

def main():
    print("ğŸš€ å¼€å§‹èšåˆ RSS æº...\n")

    # èšåˆæ‰€æœ‰å†…å®¹
    all_items = aggregate_all()

    # ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š
    report = format_detailed_report(all_items, top_n=5)

    # ä¿å­˜åˆ°æ–‡ä»¶
    output_file = f"/tmp/tech_news_{datetime.now().strftime('%Y%m%d')}.md"
    with open(output_file, "w", encoding="utf-8") as f:
        f.write(report)

    print("\nâœ… å®Œæˆï¼")
    print(f"ğŸ“„ æŠ¥å‘Šå·²ä¿å­˜ï¼š{output_file}")
    print(f"\n{report}")

    # ä¿å­˜ JSON ç»“æœ
    json_file = f"/tmp/tech_news_{datetime.now().strftime('%Y%m%d')}.json"
    with open(json_file, "w", encoding="utf-8") as f:
        json.dump(all_items, f, ensure_ascii=False, indent=2)
    print(f"ğŸ“Š JSON æ•°æ®ï¼š{json_file}")

if __name__ == "__main__":
    main()
