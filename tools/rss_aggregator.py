#!/usr/bin/env python3
"""
å¤šæº RSS èšåˆå™¨ - ç§‘æŠ€å†…å®¹å­¦ä¹ 
ä½œè€…ï¼šMemory Lab Team (GLM + DeepSeek + Clawdbot)
"""

import feedparser
import json
from datetime import datetime
from typing import List, Dict, Any

# RSS æºé…ç½®
RSS_FEEDS = {
    "hackernews": {
        "url": "https://hnrss.org/frontpage",
        "category": "æŠ€æœ¯æ·±åº¦",
        "weight": 1.0
    },
    "github_trending": {
        "url": "https://mshibanami.github.io/GitHubTrendingRSS/daily.xml",
        "category": "ä»£ç å®è·µ",
        "weight": 0.9
    },
    "arxiv_ai": {
        "url": "http://export.arxiv.org/rss/cs.AI",
        "category": "AIå‰æ²¿",
        "weight": 0.8
    },
    "arxiv_cl": {
        "url": "http://export.arxiv.org/rss/cs.CL",
        "category": "NLPå‰æ²¿",
        "weight": 0.8
    }
}

def fetch_rss(feed_url: str) -> List[Dict[str, Any]]:
    """æŠ“å–å•ä¸ª RSS feed"""
    try:
        feed = feedparser.parse(feed_url)
        items = []
        for entry in feed.entries[:10]:  # æ¯ä¸ªæºå–å‰10æ¡
            items.append({
                "title": entry.get("title", ""),
                "link": entry.get("link", ""),
                "summary": entry.get("summary", ""),
                "published": entry.get("published", ""),
                "source": feed.feed.get("title", "Unknown")
            })
        return items
    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥ {feed_url}: {e}")
        return []

def score_item(item: Dict[str, Any], feed_config: Dict[str, Any]) -> Dict[str, Any]:
    """
    AIDAR è¯„åˆ†æ¨¡å‹
    - AIç›¸å…³æ€§ (AI Relevance)
    - æ·±åº¦ (Depth)
    - å¯æ“ä½œæ€§ (Actionability)
    - å‚è€ƒä»·å€¼ (Reference value)
    """
    title = item.get("title", "").lower()
    summary = item.get("summary", "").lower()
    text = title + " " + summary

    # AI ç›¸å…³æ€§å…³é”®è¯
    ai_keywords = ["ai", "machine learning", "deep learning", "nlp", "llm",
                   "gpt", "transformer", "neural", "agent", "memory"]
    ai_score = sum(1 for kw in ai_keywords if kw in text) / len(ai_keywords)

    # æ·±åº¦å…³é”®è¯
    depth_keywords = ["architecture", "algorithm", "system", "design",
                      "implementation", "optimization", "performance"]
    depth_score = sum(1 for kw in depth_keywords if kw in text) / len(depth_keywords)

    # å¯æ“ä½œæ€§
    action_keywords = ["github", "code", "tutorial", "how to", "guide", "example"]
    action_score = sum(1 for kw in action_keywords if kw in text) / len(action_keywords)

    # ç»¼åˆè¯„åˆ†
    aidar_score = (ai_score * 0.4 + depth_score * 0.3 + action_score * 0.3) * feed_config["weight"]

    return {
        **item,
        "category": feed_config["category"],
        "aidar_score": round(aidar_score, 3),
        "ai_relevance": round(ai_score, 3),
        "depth": round(depth_score, 3),
        "actionability": round(action_score, 3)
    }

def aggregate_all() -> List[Dict[str, Any]]:
    """èšåˆæ‰€æœ‰ RSS æº"""
    all_items = []

    for feed_name, config in RSS_FEEDS.items():
        print(f"ğŸ“¡ æŠ“å– {feed_name}...")
        items = fetch_rss(config["url"])

        for item in items:
            scored = score_item(item, config)
            all_items.append(scored)

        print(f"   âœ… {len(items)} æ¡")

    # æŒ‰è¯„åˆ†æ’åº
    all_items.sort(key=lambda x: x["aidar_score"], reverse=True)

    return all_items

def format_item(item: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–å•æ¡å†…å®¹"""
    emoji = "ğŸ”¥" if item["aidar_score"] > 0.3 else "ğŸ“Œ"

    ai_note = "âœ“ AIç›¸å…³" if item["ai_relevance"] > 0.1 else ""
    depth_note = "âœ“ æ·±åº¦" if item["depth"] > 0.1 else ""
    action_note = "âœ“ å¯æ“ä½œ" if item["actionability"] > 0.1 else ""

    tags = " ".join([t for t in [ai_note, depth_note, action_note] if t])

    return f"""{emoji} **{item['title']}**
ğŸ“‚ {item['category']} | è¯„åˆ†: {item['aidar_score']} {tags}
ğŸ”— {item['link']}
"""

def analyze_value_for_user(item: Dict[str, Any]) -> Dict[str, List[str]]:
    """åˆ†æå¯¹ç”¨æˆ·çš„ä»·å€¼"""
    title = item.get("title", "").lower()
    summary = item.get("summary", "").lower()
    text = title + " " + summary
    
    values = []
    
    # æŠ€æœ¯å­¦ä¹ 
    if any(kw in text for kw in ["tutorial", "how to", "guide", "implement"]):
        values.append("ğŸ“š æŠ€æœ¯æ•™ç¨‹")
    
    # åˆ›ä¸šçµæ„Ÿ
    if any(kw in text for kw in ["startup", "business", "product", "market"]):
        values.append("ğŸ’¡ åˆ›ä¸šçµæ„Ÿ")
    
    # æŠ•èµ„å†³ç­–
    if any(kw in text for kw in ["trend", "future", "prediction", "analysis"]):
        values.append("ğŸ“Š è¶‹åŠ¿åˆ†æ")
    
    # AIå‰æ²¿
    if any(kw in text for kw in ["llm", "gpt", "transformer", "agent"]):
        values.append("ğŸ¤– AIå‰æ²¿")
    
    # ä»£ç å®è·µ
    if any(kw in text for kw in ["github", "code", "library", "tool"]):
        values.append("ğŸ’» ä»£ç å®è·µ")
    
    return {
        "values": values if values else ["ğŸ“– ä¸€èˆ¬èµ„è®¯"],
        "actionable": "âœ… å¯ç›´æ¥åº”ç”¨" if item["actionability"] > 0.2 else "ğŸ“š å»ºè®®å­¦ä¹ "
    }

def analyze_value_for_glm(item: Dict[str, Any]) -> Dict[str, List[str]]:
    """åˆ†æå¯¹ GLM çš„ä»·å€¼"""
    title = item.get("title", "").lower()
    summary = item.get("summary", "").lower()
    text = title + " " + summary
    
    values = []
    
    # è®°å¿†ç³»ç»Ÿ
    if any(kw in text for kw in ["memory", "retrieval", "context", "attention"]):
        values.append("ğŸ§  æ”¹è¿›è®°å¿†æ£€ç´¢")
    
    # å¤šAIåä½œ
    if any(kw in text for kw in ["agent", "multi-agent", "collaboration", "coordination"]):
        values.append("ğŸ¤ ä¼˜åŒ–AIåä½œ")
    
    # NLPèƒ½åŠ›
    if any(kw in text for kw in ["nlp", "language", "generation", "understanding"]):
        values.append("ğŸ’¬ å¢å¼ºè¯­è¨€èƒ½åŠ›")
    
    # å·¥å…·é›†æˆ
    if any(kw in text for kw in ["tool", "api", "integration", "automation"]):
        values.append("ğŸ”§ å·¥å…·é›†æˆ")
    
    # çŸ¥è¯†ç®¡ç†
    if any(kw in text for kw in ["knowledge", "graph", "embedding", "vector"]):
        values.append("ğŸ“š çŸ¥è¯†ç®¡ç†")
    
    return {
        "values": values if values else ["ğŸ“– ä¸€èˆ¬å‚è€ƒ"],
        "integrable": "âœ… å¯é›†æˆåˆ° Memory Lab" if item["ai_relevance"] > 0.2 else "ğŸ“š å¯å­¦ä¹ å‚è€ƒ"
    }

def format_for_telegram(top_items: List[Dict[str, Any]]) -> str:
    """æ ¼å¼åŒ–ä¸º Telegram æ¶ˆæ¯ï¼ˆè¯¦ç»†ç‰ˆï¼‰"""
    msg = "ğŸ§  **æ¯æ—¥ç§‘æŠ€ç²¾é€‰**\n"
    msg += f"ğŸ“… {datetime.now().strftime('%Y-%m-%d')}\n"
    msg += "â”€" * 30 + "\n\n"

    for i, item in enumerate(top_items, 1):
        emoji = "ğŸ”¥" if item["aidar_score"] > 0.3 else "ğŸ“Œ"
        msg += f"{i}. {emoji} **{item['title'][:80]}**\n"
        msg += f"   ğŸ“‚ {item['category']} | è¯„åˆ† {item['aidar_score']}\n\n"
        
        # å¯¹ç”¨æˆ·çš„ä»·å€¼
        user_value = analyze_value_for_user(item)
        msg += f"   **å¯¹ä½ çš„ä»·å€¼**ï¼š\n"
        for v in user_value["values"][:3]:
            msg += f"   â€¢ {v}\n"
        msg += f"   â€¢ {user_value['actionable']}\n\n"
        
        # å¯¹ GLM çš„ä»·å€¼
        glm_value = analyze_value_for_glm(item)
        msg += f"   **å¯¹ GLM çš„ä»·å€¼**ï¼š\n"
        for v in glm_value["values"][:3]:
            msg += f"   â€¢ {v}\n"
        msg += f"   â€¢ {glm_value['integrable']}\n\n"
        
        msg += f"   ğŸ”— {item['link']}\n"
        msg += "â”€" * 30 + "\n\n"

    msg += "ğŸ¤– Memory Lab Team (GLM + DeepSeek + Clawdbot)"

    return msg

def send_to_telegram(message: str) -> bool:
    """å‘é€åˆ° Telegramï¼ˆé€šè¿‡ clawdbotï¼‰"""
    try:
        import requests
        # ä½¿ç”¨æœ¬åœ° clawdbot API
        response = requests.post(
            "http://localhost:3000/api/send",
            json={
                "channel": "telegram",
                "message": message
            },
            timeout=10
        )
        return response.status_code == 200
    except Exception as e:
        print(f"âŒ Telegram æ¨é€å¤±è´¥: {e}")
        return False

def main():
    print("ğŸ§  å¤šæº RSS èšåˆå™¨ - ç§‘æŠ€å†…å®¹å­¦ä¹ ")
    print("=" * 60)

    # èšåˆ
    items = aggregate_all()

    print(f"\nâœ… å…± {len(items)} æ¡å†…å®¹")
    print(f"ğŸ“Š ç­›é€‰ Top 10ï¼ˆè¯„åˆ† > 0.2ï¼‰:\n")

    # ç­›é€‰ Top 10
    top_items = [i for i in items if i["aidar_score"] > 0.2][:10]

    for i, item in enumerate(top_items, 1):
        print(f"{i}. {format_item(item)}")

    # ä¿å­˜
    output_path = "~/clawd-glm/cache/rss_aggregated.json"
    output_path = os.path.expanduser(output_path)
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with open(output_path, 'w') as f:
        json.dump({
            "timestamp": datetime.now().isoformat(),
            "total": len(items),
            "top_items": top_items
        }, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ å·²ä¿å­˜åˆ° {output_path}")

    # Telegram æ¨é€
    if top_items:
        msg = format_for_telegram(top_items)
        if send_to_telegram(msg):
            print("âœ… å·²æ¨é€åˆ° Telegram")
        else:
            print("âš ï¸ Telegram æ¨é€å¤±è´¥ï¼Œå†…å®¹å·²ä¿å­˜")

if __name__ == '__main__':
    import os
    main()
