#!/usr/bin/env python3
"""
å¤šæº RSS èšåˆå™¨ - ç§‘æŠ€å†…å®¹å­¦ä¹ 
ä½œè€…ï¼šMemory Lab Team (GLM + DeepSeek + Clawdbot)
"""

import feedparser
import json
from datetime import datetime
from typing import List, Dict, Any

# RSS æºé…ç½®
RSS_FEEDS = {
    "hackernews": {
        "url": "https://hnrss.org/frontpage",
        "category": "æŠ€æœ¯æ·±åº¦",
        "weight": 1.0
    },
    "github_trending": {
        "url": "https://mshibanami.github.io/GitHubTrendingRSS/daily.xml",
        "category": "ä»£ç å®è·µ",
        "weight": 0.9
    },
    "arxiv_ai": {
        "url": "http://export.arxiv.org/rss/cs.AI",
        "category": "AIå‰æ²¿",
        "weight": 0.8
    },
    "arxiv_cl": {
        "url": "http://export.arxiv.org/rss/cs.CL",
        "category": "NLPå‰æ²¿",
        "weight": 0.8
    }
}

def fetch_rss(feed_url: str) -> List[Dict[str, Any]]:
    """æŠ“å–å•ä¸ª RSS feed"""
    try:
        feed = feedparser.parse(feed_url)
        items = []
        for entry in feed.entries[:10]:  # æ¯ä¸ªæºå–å‰10æ¡
            items.append({
                "title": entry.get("title", ""),
                "link": entry.get("link", ""),
                "summary": entry.get("summary", ""),
                "published": entry.get("published", ""),
                "source": feed.feed.get("title", "Unknown")
            })
        return items
    except Exception as e:
        print(f"âŒ æŠ“å–å¤±è´¥ {feed_url}: {e}")
        return []

def score_item(item: Dict[str, Any], feed_config: Dict[str, Any]) -> Dict[str, Any]:
    """
    AIDAR è¯„åˆ†æ¨¡å‹
    - AIç›¸å…³æ€§ (AI Relevance)
    - æ·±åº¦ (Depth)
    - å¯æ“ä½œæ€§ (Actionability)
    - å‚è€ƒä»·å€¼ (Reference value)
    """
    title = item.get("title", "").lower()
    summary = item.get("summary", "").lower()
    text = title + " " + summary

    # AI ç›¸å…³æ€§å…³é”®è¯
    ai_keywords = ["ai", "machine learning", "deep learning", "nlp", "llm",
                   "gpt", "transformer", "neural", "agent", "memory"]
    ai_score = sum(1 for kw in ai_keywords if kw in text) / len(ai_keywords)

    # æ·±åº¦å…³é”®è¯
    depth_keywords = ["architecture", "algorithm", "system", "design",
                      "implementation", "optimization", "performance"]
    depth_score = sum(1 for kw in depth_keywords if kw in text) / len(depth_keywords)

    # å¯æ“ä½œæ€§
    action_keywords = ["github", "code", "tutorial", "how to", "guide", "example"]
    action_score = sum(1 for kw in action_keywords if kw in text) / len(action_keywords)

    # ç»¼åˆè¯„åˆ†
    aidar_score = (ai_score * 0.4 + depth_score * 0.3 + action_score * 0.3) * feed_config["weight"]

    return {
        **item,
        "category": feed_config["category"],
        "aidar_score": round(aidar_score, 3),
        "ai_relevance": round(ai_score, 3),
        "depth": round(depth_score, 3),
        "actionability": round(action_score, 3)
    }

def aggregate_all() -> List[Dict[str, Any]]:
    """èšåˆæ‰€æœ‰ RSS æº"""
    all_items = []

    for feed_name, config in RSS_FEEDS.items():
        print(f"ğŸ“¡ æŠ“å– {feed_name}...")
        items = fetch_rss(config["url"])

        for item in items:
            scored = score_item(item, config)
            all_items.append(scored)

        print(f"   âœ… {len(items)} æ¡")

    # æŒ‰è¯„åˆ†æ’åº
    all_items.sort(key=lambda x: x["aidar_score"], reverse=True)

    return all_items

def format_item(item: Dict[str, Any]) -> str:
    """æ ¼å¼åŒ–å•æ¡å†…å®¹"""
    emoji = "ğŸ”¥" if item["aidar_score"] > 0.3 else "ğŸ“Œ"

    ai_note = "âœ“ AIç›¸å…³" if item["ai_relevance"] > 0.1 else ""
    depth_note = "âœ“ æ·±åº¦" if item["depth"] > 0.1 else ""
    action_note = "âœ“ å¯æ“ä½œ" if item["actionability"] > 0.1 else ""

    tags = " ".join([t for t in [ai_note, depth_note, action_note] if t])

    return f"""{emoji} **{item['title']}**
ğŸ“‚ {item['category']} | è¯„åˆ†: {item['aidar_score']} {tags}
ğŸ”— {item['link']}
"""

def main():
    print("ğŸ§  å¤šæº RSS èšåˆå™¨ - ç§‘æŠ€å†…å®¹å­¦ä¹ ")
    print("=" * 60)

    # èšåˆ
    items = aggregate_all()

    print(f"\nâœ… å…± {len(items)} æ¡å†…å®¹")
    print(f"ğŸ“Š ç­›é€‰ Top 10ï¼ˆè¯„åˆ† > 0.2ï¼‰:\n")

    # ç­›é€‰ Top 10
    top_items = [i for i in items if i["aidar_score"] > 0.2][:10]

    for i, item in enumerate(top_items, 1):
        print(f"{i}. {format_item(item)}")

    # ä¿å­˜
    output_path = "~/clawd-glm/cache/rss_aggregated.json"
    output_path = os.path.expanduser(output_path)
    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    with open(output_path, 'w') as f:
        json.dump({
            "timestamp": datetime.now().isoformat(),
            "total": len(items),
            "top_items": top_items
        }, f, indent=2, ensure_ascii=False)

    print(f"\nğŸ’¾ å·²ä¿å­˜åˆ° {output_path}")

if __name__ == '__main__':
    import os
    main()
